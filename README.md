# LightCBAM-ResNet  
*A Lightweight Attention-Enhanced Backbone for Camera Pose Estimation*

This repository presents our final project for UCLAâ€™s MATH 156 course. We improve upon the original PoseNet framework by integrating the Convolutional Block Attention Module (CBAM) into a ResNet backbone for camera pose estimation. Our CBAM-augmented model demonstrates better convergence and generalization performance compared to baseline architectures like VGG16 and vanilla ResNet.

---

## ğŸš€ Highlights

- Replaces PoseNetâ€™s VGG16 backbone with ResNet-50 pluse CBAM attention modules 
- Compares learned vs. fixed loss weight (CameraPoseLoss vs. static MSE)  
- Shows faster convergence and less overfitting in CBAM-enhanced models  

---

## ğŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ configs/                # YAML config files for each experiment
â”œâ”€â”€ data_preparation.py    # Dataset loading and preprocessing
â”œâ”€â”€ pipeline.py            # Main training script
â”œâ”€â”€ main.ipynb             # Sample experiment notebook
â”œâ”€â”€ figures/               # Loss curve visualizations
â”œâ”€â”€ utils/                 # Custom loss functions and CBAM modules
â””â”€â”€ README.md              # This documentation
```

---

## âš™ï¸ Installation

Install all required dependencies using:

```bash
pip install -r requirements.txt
```

---

## ğŸ“‚ Dataset

We use the **Kingâ€™s College dataset** from the original PoseNet paper.

- Make sure the dataset is downloaded from [here](https://www.repository.cam.ac.uk/items/53788265-cb98-42ee-b85b-7a0cbc8eddb3).  
- Set the correct path in your config file under `configs/*.yaml`.

---

## â–¶ï¸ How to Run

1. Prepare the dataset directory.  
2. Choose and adjust a config file (e.g., `configs/resnet_cbam.yaml`).  
3. Run the training:

```bash
python pipeline.py --config configs/resnet_cbam.yaml
```

4. Training logs and loss figures will be saved in the `figures/` folder.

---

## ğŸ“ˆ Results

Loss curves show:

- **CBAM accelerates convergence** â€” loss drops faster in early epochs.  
- **Better generalization** â€” ResNet+CBAM keeps training and validation loss close.  
- **Learned CameraPoseLoss** outperforms static loss in both smoothness and final values.

### ğŸ“‰ Example Visualizations

| Learned Loss Log | Static Loss Log |
|------------------|-----------------|
| ![learned](figures/Learned_Loss_Logarithmic.png) | ![static](figures/Static_Loss_Logarithmic.png) |

---


## ğŸ“š References
The inituition and implementation of ResNet with CBAM are from the papers [CBAM: Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521) and [ASA for Multi-Scene APR: Activating Self-Attention for Multi-Scene Absolute Pose Regression](https://arxiv.org/abs/2411.01443)
- Kendall et al., *PoseNet*  
  [https://arxiv.org/abs/1505.07427](https://arxiv.org/abs/1505.07427)

- Woo et al., *CBAM: Convolutional Block Attention Module*  
  [https://arxiv.org/abs/1807.06521](https://arxiv.org/abs/1807.06521)

---

## ğŸ“ Report

ğŸ“„ You can find the full technical write-up [here](file:///Users/yuertang/Downloads/Math_156%20(2).pdf)

---

