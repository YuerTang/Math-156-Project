# LightCBAM-ResNet  
*A Lightweight Attention-Enhanced Backbone for Camera Pose Estimation*

This repository presents our final project for UCLAâ€™s MATH 156 course. We improve upon the original PoseNet framework by integrating the Convolutional Block Attention Module (CBAM) into a ResNet backbone for camera pose estimation. Our CBAM-augmented model demonstrates better convergence and generalization performance compared to baseline architectures like VGG16 and vanilla ResNet.
Full Report: [here](Math156_Final_Report.pdf)

---
---

## ğŸš€ Highlights

- Replaces PoseNetâ€™s VGG16 backbone with ResNet-50 pluse CBAM attention modules 
- Compares learned vs. fixed loss weight (CameraPoseLoss vs. static MSE)  
- Shows faster convergence and less overfitting in CBAM-enhanced models  

---

## ğŸ—‚ï¸ Project Structure
```
.
â”œâ”€â”€ baselines/                     # Backbone model definitions
â”‚   â”œâ”€â”€ ResNet50.py
â”‚   â”œâ”€â”€ VGG16.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ config_folder/                # YAML config files for experiments
â”‚   â”œâ”€â”€ cbam-ll.yaml              # CBAM + Learned Loss
â”‚   â”œâ”€â”€ cbam-sl.yaml              # CBAM + Static Loss
â”‚   â”œâ”€â”€ resnet50-ll.yaml          # ResNet50 + Learned Loss
â”‚   â”œâ”€â”€ resnet50-sl.yaml          # ResNet50 + Static Loss
â”‚   â”œâ”€â”€ vgg16-ll.yaml             # VGG16 + Learned Loss
â”‚   â””â”€â”€ vgg16-sl.yaml             # VGG16 + Static Loss
â”‚
â”œâ”€â”€ models/                       # Attention model and architecture
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ resnet_attention.py
â”‚
â”‚   â””â”€â”€ utils/                    # Custom loss functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ losses.py
â”‚
â”œâ”€â”€ data_preparation.py           # Dataset class and preprocessing
â”œâ”€â”€ pipeline.py                   # Training script (main entry point)
â”œâ”€â”€ main.ipynb                    # Jupyter notebook for demo/testing
â”œâ”€â”€ README.md                     # Project overview and documentation
â”œâ”€â”€ .gitignore                    # Git ignore file
```

---

## âš™ï¸ Installation

Install all required dependencies using:

```bash
pip install -r requirements.txt
```

---

## ğŸ“‚ Dataset

We use the **Kingâ€™s College dataset** from the original PoseNet paper.

- Make sure the dataset is downloaded from [here](https://www.repository.cam.ac.uk/items/53788265-cb98-42ee-b85b-7a0cbc8eddb3).  
- Set the correct path in your config file under `configs/*.yaml`.

---

## â–¶ï¸ How to Run

1. Prepare the dataset directory.  
2. Choose and adjust a config file (e.g., `configs/resnet_cbam.yaml`).  
3. Run the training:

```bash
python pipeline.py --config configs/resnet_cbam.yaml
```

4. Training logs and loss figures will be saved in the `figures/` folder.

---

## ğŸ“ˆ Results

Loss curves show:

- **CBAM accelerates convergence** â€” loss drops faster in early epochs.  
- **Better generalization** â€” ResNet+CBAM keeps training and validation loss close.  
- **Learned CameraPoseLoss** outperforms static loss in both smoothness and final values.
---


## ğŸ“š References
The inituition and implementation of ResNet with CBAM are from the papers [CBAM: Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521) and [ASA for Multi-Scene APR: Activating Self-Attention for Multi-Scene Absolute Pose Regression](https://arxiv.org/abs/2411.01443).
The camera pose estimation topic was inspired from [PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization][https://arxiv.org/abs/1505.07427](https://arxiv.org/abs/1505.07427)

---



